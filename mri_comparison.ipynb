{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "mri_comparison",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyas21004/mri/blob/main/mri_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# downloading the dataset"
      ],
      "metadata": {
        "id": "hqOASCC58PUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move kaggle.json to ~/.kaggle directory\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the Brain Tumor MRI Dataset\n",
        "!kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n",
        "!unzip brain-tumor-mri-dataset.zip"
      ],
      "metadata": {
        "trusted": true,
        "id": "RkrRU1FI8PUv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data loading and preprocessing"
      ],
      "metadata": {
        "id": "DX0X5MQ68PUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from transformers import AutoImageProcessor, DefaultDataCollator\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Load Hugging Face Image Processor\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "\n",
        "# Define Image Transformations for CNN models (ResNet, EfficientNet, DenseNet)\n",
        "cnn_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Define Image Transformations for Swin Transformer\n",
        "swin_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)  # Swin normalization\n",
        "])\n",
        "\n",
        "class BrainTumorDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, model_type=\"cnn\"):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.model_type = model_type\n",
        "        self.class_to_idx = {\"glioma\": 0, \"meningioma\": 1, \"notumor\": 2, \"pituitary\": 3}\n",
        "\n",
        "        for label in os.listdir(root_dir):\n",
        "            label_dir = os.path.join(root_dir, label)\n",
        "            for img_name in os.listdir(label_dir):\n",
        "                img_path = os.path.join(label_dir, img_name)\n",
        "                self.image_paths.append(img_path)\n",
        "                self.labels.append(self.class_to_idx[label])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Adjust output format depending on model type\n",
        "        if self.model_type == \"swin\":\n",
        "            return {\"pixel_values\": image, \"labels\": torch.tensor(label)}\n",
        "        else:\n",
        "            return image, torch.tensor(label)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset_cnn = BrainTumorDataset(root_dir=\"Training\", transform=cnn_transform, model_type=\"cnn\")\n",
        "test_dataset_cnn = BrainTumorDataset(root_dir=\"Testing\", transform=cnn_transform, model_type=\"cnn\")\n",
        "\n",
        "train_dataset_swin = BrainTumorDataset(root_dir=\"Training\", transform=swin_transform, model_type=\"swin\")\n",
        "test_dataset_swin = BrainTumorDataset(root_dir=\"Testing\", transform=swin_transform, model_type=\"swin\")\n",
        "\n",
        "# Use Default Data Collator for Swin Transformer\n",
        "data_collator = DefaultDataCollator(return_tensors=\"pt\")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader_cnn = DataLoader(train_dataset_cnn, batch_size=8, shuffle=True)\n",
        "test_loader_cnn = DataLoader(test_dataset_cnn, batch_size=8, shuffle=False)\n",
        "\n",
        "train_loader_swin = DataLoader(train_dataset_swin, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
        "test_loader_swin = DataLoader(test_dataset_swin, batch_size=8, shuffle=False, collate_fn=data_collator)\n",
        "\n",
        "# Print dataset size\n",
        "print(f\"Training Samples: {len(train_dataset_cnn)}, Testing Samples: {len(test_dataset_cnn)}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T07:05:22.786109Z",
          "iopub.execute_input": "2025-04-04T07:05:22.786433Z",
          "iopub.status.idle": "2025-04-04T07:05:49.089733Z",
          "shell.execute_reply.started": "2025-04-04T07:05:22.786409Z",
          "shell.execute_reply": "2025-04-04T07:05:49.088999Z"
        },
        "id": "OekZ4GLD8PUv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# training and evaluation"
      ],
      "metadata": {
        "id": "gtkAumIb8PUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models\n",
        "from transformers import SwinForImageClassification, SwinConfig\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                            f1_score, roc_auc_score, confusion_matrix,\n",
        "                            classification_report)\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Set up directories for Kaggle\n",
        "os.makedirs(\"/kaggle/working/results\", exist_ok=True)\n",
        "os.makedirs(\"/kaggle/working/plots\", exist_ok=True)\n",
        "os.makedirs(\"/kaggle/working/saved_models\", exist_ok=True)\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def initialize_models(num_classes=4):\n",
        "    \"\"\"Initialize all models with robust anti-overfitting configurations\"\"\"\n",
        "    models_dict = {}\n",
        "\n",
        "    try:\n",
        "        # ResNet50\n",
        "        resnet = models.resnet50(pretrained=True)\n",
        "        resnet.layer1 = nn.Sequential(\n",
        "            resnet.layer1,\n",
        "            nn.Dropout(0.3),\n",
        "            nn.BatchNorm2d(256)\n",
        "        )\n",
        "        resnet.layer2 = nn.Sequential(\n",
        "            resnet.layer2,\n",
        "            nn.Dropout(0.4),\n",
        "            nn.BatchNorm2d(512)\n",
        "        )\n",
        "        resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(resnet.fc.in_features, num_classes)\n",
        "        )\n",
        "        models_dict[\"ResNet50\"] = resnet.to(device)\n",
        "\n",
        "        # EfficientNetB0\n",
        "        efficientnet = models.efficientnet_b0(pretrained=True)\n",
        "        efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(efficientnet.classifier[1].in_features, num_classes)\n",
        "        )\n",
        "        efficientnet.features = nn.Sequential(\n",
        "            efficientnet.features,\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "        models_dict[\"EfficientNetB0\"] = efficientnet.to(device)\n",
        "\n",
        "        # DenseNet121\n",
        "        densenet = models.densenet121(pretrained=True)\n",
        "        densenet.features.transition1 = nn.Sequential(\n",
        "            densenet.features.transition1,\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        densenet.features.transition2 = nn.Sequential(\n",
        "            densenet.features.transition2,\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        densenet.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(densenet.classifier.in_features, num_classes)\n",
        "        )\n",
        "        models_dict[\"DenseNet121\"] = densenet.to(device)\n",
        "\n",
        "        # Swin Transformer\n",
        "        config = SwinConfig.from_pretrained(\n",
        "            \"microsoft/swin-tiny-patch4-window7-224\",\n",
        "            num_labels=num_classes,\n",
        "            attention_probs_dropout_prob=0.3,\n",
        "            hidden_dropout_prob=0.3,\n",
        "            path_dropout=0.2\n",
        "        )\n",
        "        swin = SwinForImageClassification.from_pretrained(\n",
        "            \"microsoft/swin-tiny-patch4-window7-224\",\n",
        "            config=config,\n",
        "            ignore_mismatched_sizes=True\n",
        "        )\n",
        "        if hasattr(swin, 'classifier'):\n",
        "            if isinstance(swin.classifier, nn.Linear):\n",
        "                swin.classifier = nn.Sequential(\n",
        "                    nn.Dropout(0.5),\n",
        "                    nn.Linear(swin.classifier.in_features, swin.classifier.out_features)\n",
        "                )\n",
        "        models_dict[\"SwinTransformer\"] = swin.to(device)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing models: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "    return models_dict\n",
        "\n",
        "def save_model_on_error(model, model_name, epoch, error):\n",
        "    path = f\"/kaggle/working/saved_models/error_{model_name}_epoch{epoch}.pth\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved at {path} due to error: {str(error)}\")\n",
        "\n",
        "def train_model(model, train_loader, val_loader, model_name, epochs=15):\n",
        "    \"\"\"Training loop with validation, early stopping, and regularization\"\"\"\n",
        "    if model_name == \"SwinTransformer\":\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': [p for n, p in model.named_parameters() if 'classifier' not in n],\n",
        "             'weight_decay': 0.1, 'lr': 2e-5},\n",
        "            {'params': [p for n, p in model.named_parameters() if 'classifier' in n],\n",
        "             'weight_decay': 0.01, 'lr': 1e-4}\n",
        "        ])\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer, max_lr=1e-4, steps_per_epoch=len(train_loader), epochs=epochs,\n",
        "            pct_start=0.1, anneal_strategy='cos', div_factor=10, final_div_factor=1e4\n",
        "        )\n",
        "    else:\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in ['fc', 'classifier'])],\n",
        "             'weight_decay': 1e-4},\n",
        "            {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in ['fc', 'classifier'])],\n",
        "             'weight_decay': 0.01, 'lr': 1e-4}\n",
        "        ])\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "    best_val_acc = 0.0\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        try:\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            train_loop = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{epochs} [Train]')\n",
        "            for batch in train_loop:\n",
        "                try:\n",
        "                    if model_name == \"SwinTransformer\":\n",
        "                        inputs = batch['pixel_values'].to(device)\n",
        "                        labels = batch['labels'].to(device)\n",
        "                        outputs = model(inputs, labels=labels)\n",
        "                        loss = outputs.loss\n",
        "                        logits = outputs.logits\n",
        "                    else:\n",
        "                        inputs, labels = batch\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        logits = model(inputs)\n",
        "                        loss = criterion(logits, labels)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item()\n",
        "                    _, predicted = torch.max(logits.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    train_loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n",
        "\n",
        "                except Exception as e:\n",
        "                    save_model_on_error(model, model_name, epoch, e)\n",
        "                    raise\n",
        "\n",
        "            train_loss = running_loss / len(train_loader)\n",
        "            train_acc = 100. * correct / total\n",
        "            history['train_loss'].append(train_loss)\n",
        "            history['train_acc'].append(train_acc)\n",
        "\n",
        "            val_loss, val_acc = evaluate_model(model, val_loader, model_name)\n",
        "            history['val_loss'].append(val_loss)\n",
        "            history['val_acc'].append(val_acc)\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if val_acc > best_val_acc + 0.001:\n",
        "                best_val_acc = val_acc\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), f\"/kaggle/working/results/best_{model_name}.pth\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"\\nEarly stopping triggered at epoch {epoch + 1}\")\n",
        "                    model.load_state_dict(torch.load(f\"/kaggle/working/results/best_{model_name}.pth\"))\n",
        "                    break\n",
        "\n",
        "            print(f'Epoch {epoch + 1}/{epochs} - '\n",
        "                  f'Train Loss: {train_loss:.4f}, Acc: {train_acc:.2f}% | '\n",
        "                  f'Val Loss: {val_loss:.4f}, Acc: {val_acc:.2f}% | '\n",
        "                  f'LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
        "\n",
        "        except Exception as e:\n",
        "            save_model_on_error(model, model_name, epoch, e)\n",
        "            print(f\"Training interrupted at epoch {epoch + 1} due to: {str(e)}\")\n",
        "            break\n",
        "\n",
        "    return history\n",
        "\n",
        "\n",
        "def evaluate_model(model, loader, model_name):\n",
        "    \"\"\"Evaluate model on validation/test set\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            try:\n",
        "                if model_name == \"SwinTransformer\":\n",
        "                    inputs = batch['pixel_values'].to(device)\n",
        "                    labels = batch['labels'].to(device)\n",
        "                    outputs = model(inputs, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                    logits = outputs.logits\n",
        "                else:\n",
        "                    inputs, labels = batch\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logits = model(inputs)\n",
        "                    loss = criterion(logits, labels)\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(logits.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during evaluation batch: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    val_loss = running_loss / len(loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def comprehensive_evaluation(model, loader, model_name, class_names):\n",
        "    \"\"\"Generate comprehensive evaluation metrics\"\"\"\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            try:\n",
        "                if model_name == \"SwinTransformer\":\n",
        "                    inputs = batch['pixel_values'].to(device)\n",
        "                    labels = batch['labels'].to(device)\n",
        "                    outputs = model(inputs)\n",
        "                    if not hasattr(outputs, 'logits'):\n",
        "                        raise ValueError(\"SwinTransformer output missing logits\")\n",
        "                    logits = outputs.logits\n",
        "                else:\n",
        "                    inputs, labels = batch\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logits = model(inputs)\n",
        "\n",
        "                probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "                _, preds = torch.max(logits, 1)\n",
        "\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error during evaluation batch: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {}\n",
        "    try:\n",
        "        metrics['accuracy'] = accuracy_score(all_labels, all_preds)\n",
        "        metrics['precision'] = precision_score(all_labels, all_preds, average='weighted')\n",
        "        metrics['recall'] = recall_score(all_labels, all_preds, average='weighted')\n",
        "        metrics['f1_score'] = f1_score(all_labels, all_preds, average='weighted')\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating basic metrics: {str(e)}\")\n",
        "        metrics.update({'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0})\n",
        "\n",
        "    try:\n",
        "        metrics['roc_auc'] = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating ROC AUC: {str(e)}\")\n",
        "        metrics['roc_auc'] = 0.0\n",
        "\n",
        "    try:\n",
        "        metrics['confusion_matrix'] = confusion_matrix(all_labels, all_preds)\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating confusion matrix: {str(e)}\")\n",
        "        metrics['confusion_matrix'] = np.zeros((len(class_names), len(class_names)))\n",
        "\n",
        "    try:\n",
        "        metrics['classification_report'] = classification_report(\n",
        "            all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating classification report: {str(e)}\")\n",
        "        metrics['classification_report'] = {name: {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
        "                                          for name in class_names}\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def plot_history(history, model_name):\n",
        "    \"\"\"Plot and save training history\"\"\"\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Validation Loss')\n",
        "    plt.title(f'{model_name} - Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
        "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
        "    plt.title(f'{model_name} - Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'/kaggle/working/plots/{model_name}_training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, model_name):\n",
        "    \"\"\"Plot and save confusion matrix\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'{model_name} - Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(f'/kaggle/working/plots/{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def verify_dataloaders(cnn_loader, swin_loader):\n",
        "    \"\"\"Verify DataLoader formats\"\"\"\n",
        "    try:\n",
        "        cnn_batch = next(iter(cnn_loader))\n",
        "        if not (isinstance(cnn_batch, (tuple, list)) or len(cnn_batch) != 2):\n",
        "            raise ValueError(\"CNN DataLoader should return (inputs, labels) tuples\")\n",
        "\n",
        "        swin_batch = next(iter(swin_loader))\n",
        "        if not isinstance(swin_batch, dict) or 'pixel_values' not in swin_batch or 'labels' not in swin_batch:\n",
        "            raise ValueError(\"Swin DataLoader should return dicts with 'pixel_values' and 'labels'\")\n",
        "\n",
        "        print(\"DataLoader verification passed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"DataLoader verification failed: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def generate_comparison_table(results, class_names):\n",
        "    \"\"\"Generate and display model comparison table\"\"\"\n",
        "    print(\"\\n\\nCOMPREHENSIVE MODEL COMPARISON\")\n",
        "    print(\"=\"*120)\n",
        "    print(f\"{'Model':<20} | {'Accuracy':<8} | {'F1-Score':<8} | {'ROC AUC':<8} | {'Params (M)':<10} | {'Time (min)':<10}\")\n",
        "    print(\"-\"*120)\n",
        "\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"{model_name:<20} | {metrics['accuracy']:.4f}    | {metrics['f1_score']:.4f}    | \"\n",
        "              f\"{metrics['roc_auc']:.4f}    | {metrics['total_params']/1e6:<10.2f} | \"\n",
        "              f\"{metrics['training_time']/60:<10.2f}\")\n",
        "\n",
        "    # Generate detailed results dataframe\n",
        "    detailed_results = []\n",
        "    for model_name, metrics in results.items():\n",
        "        row = {\n",
        "            'Model': model_name,\n",
        "            'Accuracy': metrics['accuracy'],\n",
        "            'Precision': metrics['precision'],\n",
        "            'Recall': metrics['recall'],\n",
        "            'F1-Score': metrics['f1_score'],\n",
        "            'ROC AUC': metrics['roc_auc'],\n",
        "            'Total Params (M)': metrics['total_params']/1e6,\n",
        "            'Trainable Params (M)': metrics['trainable_params']/1e6,\n",
        "            'Training Time (min)': metrics['training_time']/60\n",
        "        }\n",
        "        for class_name in class_names:\n",
        "            row.update({\n",
        "                f'{class_name} Precision': metrics['classification_report'][class_name]['precision'],\n",
        "                f'{class_name} Recall': metrics['classification_report'][class_name]['recall'],\n",
        "                f'{class_name} F1': metrics['classification_report'][class_name]['f1-score']\n",
        "            })\n",
        "        detailed_results.append(row)\n",
        "\n",
        "    df_results = pd.DataFrame(detailed_results)\n",
        "\n",
        "    # Reorder columns for better readability\n",
        "    column_order = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC AUC',\n",
        "                  'Total Params (M)', 'Trainable Params (M)', 'Training Time (min)']\n",
        "    for class_name in class_names:\n",
        "        column_order.extend([f'{class_name} Precision', f'{class_name} Recall', f'{class_name} F1'])\n",
        "\n",
        "    df_results = df_results[column_order]\n",
        "    df_results.to_csv('/kaggle/working/results/model_comparison.csv', index=False)\n",
        "    print(\"\\nDetailed results saved to '/kaggle/working/results/model_comparison.csv'\")\n",
        "\n",
        "    # Generate LaTeX table\n",
        "    latex_table = df_results.to_latex(index=False, float_format=\"%.4f\",\n",
        "                                    caption=\"Model Performance Comparison\",\n",
        "                                    label=\"tab:model_comparison\")\n",
        "    with open('/kaggle/working/results/model_comparison.tex', 'w') as f:\n",
        "        f.write(latex_table)\n",
        "    print(\"LaTeX table saved to '/kaggle/working/results/model_comparison.tex'\")\n",
        "\n",
        "    return df_results\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize models and datasets\n",
        "        models_dict = initialize_models()\n",
        "        class_names = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "\n",
        "        # Verify DataLoaders are defined and have correct format\n",
        "        global train_loader_cnn, test_loader_cnn, train_loader_swin, test_loader_swin\n",
        "        verify_dataloaders(train_loader_cnn, train_loader_swin)\n",
        "\n",
        "        # Create loaders dictionary\n",
        "        loaders_dict = {\n",
        "            \"ResNet50\": (train_loader_cnn, test_loader_cnn),\n",
        "            \"EfficientNetB0\": (train_loader_cnn, test_loader_cnn),\n",
        "            \"DenseNet121\": (train_loader_cnn, test_loader_cnn),\n",
        "            \"SwinTransformer\": (train_loader_swin, test_loader_swin)\n",
        "        }\n",
        "\n",
        "        # Train and evaluate models\n",
        "        results = {}\n",
        "        for model_name, model in models_dict.items():\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Training {model_name}\")\n",
        "            print(f\"{'='*50}\")\n",
        "\n",
        "            try:\n",
        "                train_loader, test_loader = loaders_dict[model_name]\n",
        "\n",
        "                # Train model\n",
        "                start_time = time.time()\n",
        "                history = train_model(model, train_loader, test_loader, model_name, epochs=20)\n",
        "                training_time = time.time() - start_time\n",
        "\n",
        "                # Save training history\n",
        "                plot_history(history, model_name)\n",
        "\n",
        "                # Load best model for evaluation\n",
        "                model.load_state_dict(torch.load(f\"/kaggle/working/results/best_{model_name}.pth\"))\n",
        "\n",
        "                # Comprehensive evaluation\n",
        "                eval_results = comprehensive_evaluation(model, test_loader, model_name, class_names)\n",
        "                eval_results['training_time'] = training_time\n",
        "                eval_results['total_params'] = sum(p.numel() for p in model.parameters())\n",
        "                eval_results['trainable_params'] = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "                results[model_name] = eval_results\n",
        "                plot_confusion_matrix(eval_results['confusion_matrix'], class_names, model_name)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {model_name}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        # Generate comparison table and save results\n",
        "        if results:\n",
        "            comparison_df = generate_comparison_table(results, class_names)\n",
        "\n",
        "            # Print class-wise comparison\n",
        "            print(\"\\n\\nCLASS-WISE PERFORMANCE COMPARISON\")\n",
        "            print(\"=\"*90)\n",
        "            for class_name in class_names:\n",
        "                print(f\"\\n{class_name}:\")\n",
        "                print(f\"{'Model':<20} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n",
        "                print(\"-\"*50)\n",
        "                for model_name, metrics in results.items():\n",
        "                    print(f\"{model_name:<20} | {metrics['classification_report'][class_name]['precision']:<10.4f} | \"\n",
        "                          f\"{metrics['classification_report'][class_name]['recall']:<10.4f} | \"\n",
        "                          f\"{metrics['classification_report'][class_name]['f1-score']:<10.4f}\")\n",
        "        else:\n",
        "            print(\"\\nNo models were successfully trained. Check error messages above.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFatal error in main execution: {str(e)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T07:05:55.725048Z",
          "iopub.execute_input": "2025-04-04T07:05:55.725669Z",
          "iopub.status.idle": "2025-04-04T09:29:49.907514Z",
          "shell.execute_reply.started": "2025-04-04T07:05:55.725643Z",
          "shell.execute_reply": "2025-04-04T09:29:49.906615Z"
        },
        "id": "fzl-GsGY8PUw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "o7-JCEQ08PUx"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}